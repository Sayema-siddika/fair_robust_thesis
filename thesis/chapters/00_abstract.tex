\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

Machine learning systems increasingly influence high-stakes decisions in hiring, lending, and criminal justice, making fairness a critical concern. Existing fairness interventions often fail to achieve perfect equity or have unclear trade-offs between fairness, accuracy, and calibration. This thesis introduces \textbf{iterative adaptive sample weighting}, a simple yet powerful method that achieves perfect fairness on real-world datasets.

Our approach assigns higher weights to samples the model predicts correctly with high confidence, using the formula $w_i = (c_i \times r_i + \epsilon)^{1/T}$, where $c_i$ is prediction confidence, $r_i$ is correctness, and $T=0.5$ is the temperature parameter. Through iterative retraining (10--20 epochs), the method progressively reduces fairness disparities.

We evaluate on three benchmark datasets: COMPAS (recidivism), Adult (income), and German (credit). Our key findings are: (1)~\textbf{Perfect fairness achieved}: German Credit reaches equalized odds disparity of \textbf{EO=0.0} and demographic parity \textbf{DP=0.0}, the first demonstration on a real dataset; (2)~\textbf{Significant improvements}: Adult dataset shows +30.9\% fairness gain; (3)~\textbf{Fundamental trade-off}: Calibration degrades by +388--756\% (ECE) across all datasets; (4)~\textbf{Computational feasibility}: Training time <2s with zero inference overhead, enabling production deployment.

Interpretability analysis reveals the mechanism: adaptive weighting systematically upweights samples the model already handles well (confident correct predictions), focusing learning on understood patterns. This improves fairness but creates overconfidence, explaining the calibration trade-off.

We provide practical guidelines for when to use adaptive weighting (high baseline unfairness, fairness priority) and when to avoid it (calibration-critical applications, already-fair baselines). The method's simplicity (10 lines of code), zero production overhead, and ability to achieve perfect fairness make it a valuable tool for fair machine learning, though practitioners must carefully evaluate the fairness-calibration trade-off for their specific use case.

\vspace{1cm}

\noindent\textbf{Keywords:} Fairness, Machine Learning, Sample Weighting, Calibration, Equalized Odds, Algorithmic Bias

\cleardoublepage
