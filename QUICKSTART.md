# ğŸš€ Quick Start Guide
## Fair and Robust Thesis - Get Running in 10 Minutes

---

## âœ… IMMEDIATE NEXT STEPS (Day 1 â†’ Day 2 Transition)

### Step 1: Download COMPAS Dataset (2 minutes)

**Option A: Using PowerShell (Recommended)**
```powershell
cd d:\Research\fair_robust_thesis\data\raw\compas
Invoke-WebRequest -Uri "https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv" -OutFile "compas-scores-two-years.csv"
```

**Option B: Manual Download**
1. Visit: https://github.com/propublica/compas-analysis
2. Download file: `compas-scores-two-years.csv`
3. Save to: `d:\Research\fair_robust_thesis\data\raw\compas\`

**Verify**:
```powershell
Get-ChildItem data\raw\compas\
# Should show: compas-scores-two-years.csv (size ~800KB)
```

---

### Step 2: Install Dependencies (5 minutes)

**Using the setup script**:
```powershell
cd d:\Research\fair_robust_thesis
.\setup.ps1
```

**OR manually**:
```powershell
# Create environment
conda create -n thesis python=3.8 -y

# Activate
conda activate thesis

# Install PyTorch
pip install torch==1.13.0 torchvision==0.14.0 --index-url https://download.pytorch.org/whl/cpu

# Install other packages
pip install -r requirements.txt
```

**Verify Installation**:
```powershell
python -c "import torch; import numpy; import pandas; import sklearn; print('âœ“ All packages installed!')"
```

---

### Step 3: Test Data Loader (1 minute)

```powershell
python src\data_loader.py
```

**Expected Output**:
```
COMPAS dataset loaded:
  Samples: 7214
  Features: 5
  Positive rate: 45.16%
  African-American: 51.44%

Splitting data (test_size=0.3)...
  Train samples: 5050
  Test samples: 2164

Noise injection complete:
  Target noise rate: 10.0%
  Actual noise rate: 10.0%
```

âœ… If you see this â†’ Data loader works!

---

### Step 4: Run Baseline Experiment (2 minutes)

```powershell
python experiments\01_reproduce_baseline.py
```

**Expected Output**:
```
======================================================================
          BASELINE EXPERIMENT: LOGISTIC REGRESSION
======================================================================

Configuration:
  Dataset: compas
  Noise rate: 10.0%
  ...

Training baseline logistic regression...
  Epoch 20/100, Loss: 0.6523
  Epoch 40/100, Loss: 0.6301
  ...
  Epoch 100/100, Loss: 0.6075

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    FINAL RESULTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Performance Metrics:
  âœ“ Accuracy: 0.6542 (65.42%)

âš–ï¸  Fairness Metrics (lower is better):
  â€¢ Demographic Parity Disparity: 0.0987
  â€¢ Equalized Odds Disparity: 0.1234
  â€¢ Equal Opportunity Disparity: 0.0891
```

âœ… If accuracy ~65% and EO disparity ~0.12 â†’ Baseline working!

---

## ğŸ¯ TODAY'S CHECKLIST (End of Day 1)

Before you close your computer tonight:

```
âœ… Project structure created
âœ… Core files implemented:
   - src/data_loader.py
   - src/fairness/metrics.py
   - experiments/01_reproduce_baseline.py
âœ… COMPAS dataset downloaded
âœ… Dependencies installed
âœ… Baseline experiment runs successfully
âœ… Results saved to results/metrics/baseline_results.txt
âœ… PROGRESS.md updated
âœ… Committed to Git (if using version control)
```

**Git Commands** (if using Git):
```powershell
git add .
git commit -m "Day 1: Project setup + baseline implementation"
git log --oneline  # Verify commit
```

---

## ğŸ“‹ TOMORROW'S PLAN (Day 2)

### Morning (9 AM - 1 PM)

**Task 1: Read Base Paper** (2 hours)
```
PDF: https://arxiv.org/pdf/2110.14222.pdf
Focus on:
  - Section 3: Problem Formulation (30 min)
  - Section 4: Proposed Method (60 min)
  - Section 5: Experiments (30 min)

Take notes on:
  - Greedy algorithm (Algorithm 1)
  - Lambda update rule (Equation 4.2)
  - Key results (Table 1)
```

**Task 2: Implement Greedy Selector** (2 hours)
```
File to create: src/selection/greedy_selector.py

Implement:
  1. Sample loss computation
  2. Greedy selection (lowest loss samples)
  3. Fairness-aware weighting
  4. Lambda update mechanism
```

### Afternoon (2 PM - 6 PM)

**Task 3: Test Greedy Selector** (2 hours)
```
Create: experiments/02_greedy_selector.py
Run baseline vs greedy
Compare results
```

**Task 4: Download Adult & German Datasets** (2 hours)
```
Adult: https://archive.ics.uci.edu/ml/datasets/adult
German: https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)

Implement:
  - load_adult() in data_loader.py
  - load_german() in data_loader.py
```

### Evening (7 PM - 9 PM)

**Task 5: Documentation** (1 hour)
```
Update PROGRESS.md
Document Day 2 results
Plan Day 3
```

**Task 6: Commit & Backup** (30 min)
```
git add .
git commit -m "Day 2: Greedy selector + multi-dataset"
git push (if using remote)
```

---

## ğŸ†˜ TROUBLESHOOTING

### Problem: "COMPAS dataset not found"
**Solution**:
```powershell
# Check if file exists
Test-Path data\raw\compas\compas-scores-two-years.csv

# If False, download again:
cd data\raw\compas
Invoke-WebRequest -Uri "https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv" -OutFile "compas-scores-two-years.csv"
```

### Problem: "Module 'torch' not found"
**Solution**:
```powershell
# Verify environment is activated
conda activate thesis

# Reinstall PyTorch
pip install torch==1.13.0 torchvision==0.14.0
```

### Problem: "Intel Arc GPU not detected"
**Solution**:
```
Don't worry! CPU is fine for this thesis.
PyTorch will automatically use CPU.
Your Arc A770 can be configured later if needed.
```

### Problem: Baseline accuracy very low (<50%)
**Solution**:
```
Check:
1. Data loaded correctly? (should be ~7K samples)
2. Features standardized? (should have mean~0, std~1)
3. Labels binary? (should be 0 or 1)
4. Enough epochs? (try 200 instead of 100)
```

---

## ğŸ“ GETTING HELP

### Stack Overflow Strategy
1. Search: "pytorch binary classification"
2. Search: "fairness metrics machine learning"
3. Search: "meta-learning sample selection"

### Papers to Reference
- Base paper: Roh et al. (NeurIPS 2021)
- MAML: Finn et al. (ICML 2017)
- FairBatch: Roh et al. (ICLR 2021)

### Code Examples
- Base paper repo: https://github.com/yuji-roh/fair-robust-selection
- FairBatch repo: https://github.com/yuji-roh/fairbatch

---

## ğŸ“ WEEKLY GOALS REMINDER

### Week 1 (Days 1-7)
**Primary Goal**: Get baseline working on 3 datasets

**Deliverables**:
- [ ] Baseline experiments on COMPAS, Adult, German
- [ ] Greedy selector implemented
- [ ] Meta-selector architecture designed
- [ ] Week 1 report (2 pages)

**Success Metric**: Reproduce base paper Table 1 (within 2%)

---

## ğŸ“Š DAILY TRACKING

Create a simple `DAILY_LOG.md`:

```markdown
# Daily Log

## Day 1 (Dec 6)
- Hours worked: 5h
- Tasks completed: 4/4
- Blockers: None
- Mood: ğŸ˜Š Excited!

## Day 2 (Dec 7)
- Hours worked: __h
- Tasks completed: __/6
- Blockers: ______
- Mood: ___
```

---

## ğŸ SUCCESS INDICATORS

You're on track if:

**End of Day 1**:
- âœ… Can run baseline experiment
- âœ… Understand fairness metrics
- âœ… Dataset loads correctly

**End of Day 2**:
- âœ… Greedy selector implemented
- âœ… Results match base paper (roughly)
- âœ… Adult & German datasets working

**End of Week 1**:
- âœ… Meta-selector training
- âœ… Beats greedy on at least 1 dataset
- âœ… Confident in understanding

**End of Week 2**:
- âœ… Full system working
- âœ… Shows improvement over baseline
- âœ… Ready for full experiments

---

## ğŸ’ª MOTIVATION

**You've completed Day 1!** ğŸ‰

- âœ… 700+ lines of code written
- âœ… 20+ files created
- âœ… Project structure complete
- âœ… Core utilities implemented

**Progress**: 3% â†’ Target: 100% in 30 days

**Tomorrow's Progress**: 3% â†’ 10%

---

**Keep Going! One Day at a Time! ğŸš€**

---

**Last Updated**: December 6, 2025, 11:30 PM
**Next Task**: Download COMPAS dataset (2 minutes)
